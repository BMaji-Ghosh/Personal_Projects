{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b3c4f8-2561-4328-ac47-fa40b453b4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Reading data...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 338199 entries, 0 to 338198\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   neo_id                  338199 non-null  int64  \n",
      " 1   name                    338199 non-null  object \n",
      " 2   absolute_magnitude      338171 non-null  float64\n",
      " 3   estimated_diameter_min  338171 non-null  float64\n",
      " 4   estimated_diameter_max  338171 non-null  float64\n",
      " 5   orbiting_body           338199 non-null  object \n",
      " 6   relative_velocity       338199 non-null  float64\n",
      " 7   miss_distance           338199 non-null  float64\n",
      " 8   is_hazardous            338199 non-null  bool   \n",
      "dtypes: bool(1), float64(5), int64(1), object(2)\n",
      "memory usage: 21.0+ MB\n",
      "None \n",
      "\n",
      "📉 Missing values before cleaning:\n",
      " neo_id                     0\n",
      "name                       0\n",
      "absolute_magnitude        28\n",
      "estimated_diameter_min    28\n",
      "estimated_diameter_max    28\n",
      "orbiting_body              0\n",
      "relative_velocity          0\n",
      "miss_distance              0\n",
      "is_hazardous               0\n",
      "dtype: int64 \n",
      "\n",
      "✅ After dropping nulls: (338171, 9)\n",
      "✅ Removed outliers from absolute_magnitude: 389 rows dropped\n",
      "✅ Removed outliers from estimated_diameter_min: 26051 rows dropped\n",
      "✅ Removed outliers from estimated_diameter_max: 11795 rows dropped\n",
      "✅ Removed outliers from relative_velocity: 4168 rows dropped\n",
      "✅ Removed outliers from miss_distance: 0 rows dropped\n",
      "\n",
      "⚖️ Applying SMOTE for class balancing...\n",
      "Before SMOTE:\n",
      " is_hazardous\n",
      "False    210863\n",
      "True      25751\n",
      "Name: count, dtype: int64\n",
      "After SMOTE:\n",
      " is_hazardous\n",
      "False    210863\n",
      "True     210863\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🧠 Training Logistic Regression...\n",
      "\n",
      "📊 Logistic Regression - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.46      0.61     52716\n",
      "        True       0.13      0.69      0.23      6438\n",
      "\n",
      "    accuracy                           0.49     59154\n",
      "   macro avg       0.53      0.57      0.42     59154\n",
      "weighted avg       0.84      0.49      0.57     59154\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24270 28446]\n",
      " [ 2001  4437]]\n",
      "ROC-AUC Score: 0.6222117674477228\n",
      "\n",
      "🧠 Training Random Forest...\n",
      "\n",
      "📊 Random Forest - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.96      0.96     52716\n",
      "        True       0.66      0.65      0.65      6438\n",
      "\n",
      "    accuracy                           0.93     59154\n",
      "   macro avg       0.81      0.80      0.81     59154\n",
      "weighted avg       0.92      0.93      0.93     59154\n",
      "\n",
      "Confusion Matrix:\n",
      " [[50607  2109]\n",
      " [ 2284  4154]]\n",
      "ROC-AUC Score: 0.9552767806229425\n"
     ]
    }
   ],
   "source": [
    "# nasa_ml_project.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "print(\"📥 Reading data...\")\n",
    "df = pd.read_csv(\"nearest-earth-objects(1910-2024).csv.zip\")  # Replace with your actual file path\n",
    "print(df.info(), \"\\n\")\n",
    "\n",
    "# Step 2: Check & Handle Missing Values\n",
    "print(\"📉 Missing values before cleaning:\\n\", df.isnull().sum(), \"\\n\")\n",
    "df.dropna(inplace=True)\n",
    "print(f\"✅ After dropping nulls: {df.shape}\")\n",
    "\n",
    "# Step 3: Handle Outliers using IQR\n",
    "def remove_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    before = data.shape[0]\n",
    "    data = data[(data[column] >= lower) & (data[column] <= upper)]\n",
    "    removed = before - data.shape[0]\n",
    "    print(f\"✅ Removed outliers from {column}: {removed} rows dropped\")\n",
    "    return data\n",
    "\n",
    "cols_to_clean = ['absolute_magnitude', 'estimated_diameter_min',\n",
    "                 'estimated_diameter_max', 'relative_velocity', 'miss_distance']\n",
    "\n",
    "for col in cols_to_clean:\n",
    "    df = remove_outliers_iqr(df, col)\n",
    "\n",
    "# Step 4: Feature Engineering\n",
    "df.drop(['neo_id', 'name', 'orbiting_body'], axis=1, inplace=True)\n",
    "X = df.drop('is_hazardous', axis=1)\n",
    "y = df['is_hazardous']\n",
    "\n",
    "# Step 5: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Step 6: SMOTE Balancing\n",
    "print(\"\\n⚖️ Applying SMOTE for class balancing...\")\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
    "print(\"Before SMOTE:\\n\", y_train.value_counts())\n",
    "print(\"After SMOTE:\\n\", y_train_bal.value_counts())\n",
    "\n",
    "# Step 7: Train Logistic Regression\n",
    "print(\"\\n🧠 Training Logistic Regression...\")\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_bal, y_train_bal)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"\\n📊 Logistic Regression - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, lr.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "# Step 8: Train Random Forest\n",
    "print(\"\\n🧠 Training Random Forest...\")\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_bal, y_train_bal)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"\\n📊 Random Forest - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff55e3f-aee0-4755-85a9-c8a0bc921858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
